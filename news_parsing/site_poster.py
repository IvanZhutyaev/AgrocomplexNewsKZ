import os
from datetime import datetime

import requests
import json
from bs4 import BeautifulSoup
from config import SITE_URL, SITE_LOGIN, SITE_PASSWORD
import re
session = requests.Session()


def login_to_site() -> bool:
    """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏ Voyager"""
    login_url = f"{SITE_URL}/admin/login"
    try:
        print("üîë –í—Ö–æ–¥–∏–º –≤ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å...")

        # –ü–æ–ª—É—á–∞–µ–º CSRF —Ç–æ–∫–µ–Ω —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ª–æ–≥–∏–Ω–∞
        login_page = session.get(login_url, timeout=10)
        soup = BeautifulSoup(login_page.text, "html.parser")
        token_tag = soup.find("input", {"name": "_token"})
        csrf_token = token_tag["value"] if token_tag else None

        if not csrf_token:
            print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω CSRF —Ç–æ–∫–µ–Ω –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ª–æ–≥–∏–Ω–∞")
            return False

        data = {
            "email": SITE_LOGIN,
            "password": SITE_PASSWORD,
            "_token": csrf_token
        }

        resp = session.post(login_url, data=data, timeout=10)
        if "voyager-dashboard" in resp.text or "logout" in resp.text:
            print("‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ")
            return True
        else:
            print("‚ö†Ô∏è –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏–Ω/–ø–∞—Ä–æ–ª—å.")
            return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        return False


def extract_title_and_body(text: str):
    """–†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ç–µ–ª–æ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = text.strip()

    # –ò—â–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å - –¥–≤–æ–π–Ω–æ–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
    if "\n\n" in text:
        parts = text.split("\n\n", 1)
        title = parts[0].strip()
        body = parts[1].strip()
    else:
        # –ò—â–µ–º –ø–µ—Ä–≤—ã–π –æ–¥–∏–Ω–∞—Ä–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
        lines = text.split("\n")
        if len(lines) > 1:
            title = lines[0].strip()
            body = "\n".join(lines[1:]).strip()
        else:
            # –¢–æ–ª—å–∫–æ –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞
            title = text
            body = ""

    # –û—á–∏—â–∞–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    title = re.sub(r'\s+', ' ', title)  # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –æ–¥–∏–Ω
    title = title[:255]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

    # –û—á–∏—â–∞–µ–º —Ç–µ–ª–æ —Ç–µ–∫—Å—Ç–∞
    body = re.sub(r'\s+', ' ', body)  # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –æ–¥–∏–Ω

    print(f"üìÑ –ò–∑–≤–ª–µ—á–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
    print(f"üìÑ –ò–∑–≤–ª–µ—á–µ–Ω —Ç–µ–∫—Å—Ç: {len(body)} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"üìÑ –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤): {body[:100]}...")

    return title, body

def get_csrf_token_for_create() -> str:
    """–ü–æ–ª—É—á–∞–µ–º CSRF —Ç–æ–∫–µ–Ω —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏"""
    create_url = f"{SITE_URL}/admin/news/create"
    try:
        resp = session.get(create_url, timeout=10)
        if resp.status_code != 200:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ–∑–¥–∞–Ω–∏—è: {resp.status_code}")
            return None

        soup = BeautifulSoup(resp.text, "html.parser")

        # –ò—â–µ–º –í–°–ï —Ñ–æ—Ä–º—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        forms = soup.find_all('form')
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Ñ–æ—Ä–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(forms)}")

        for i, form in enumerate(forms):
            action = form.get('action', '')
            method = form.get('method', '')
            print(f"  –§–æ—Ä–º–∞ {i + 1}: action='{action}', method='{method}'")

        # –ò—â–µ–º —Ñ–æ—Ä–º—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º action (–æ–±—ã—á–Ω–æ action='' –∏–ª–∏ action='/admin/news')
        target_form = None
        for form in forms:
            action = form.get('action', '')
            # –ò—â–µ–º —Ñ–æ—Ä–º—É, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ –≤–µ–¥–µ—Ç –Ω–∞ logout –∏ –Ω–µ –∏–º–µ–µ—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ action
            if 'logout' not in action and not action.startswith('/admin/logout'):
                target_form = form
                break

        if not target_form and forms:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â—É—é, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Ñ–æ—Ä–º—É
            target_form = forms[0]

        if not target_form:
            print("‚ùå –§–æ—Ä–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
            return None

        print("‚úÖ –§–æ—Ä–º–∞ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞–π–¥–µ–Ω–∞")

        # –ò—â–µ–º CSRF —Ç–æ–∫–µ–Ω –≤ —Ñ–æ—Ä–º–µ
        token_tag = target_form.find("input", {"name": "_token"})
        if token_tag:
            csrf_token = token_tag["value"]
            print(f"‚úÖ CSRF —Ç–æ–∫–µ–Ω –Ω–∞–π–¥–µ–Ω: {csrf_token[:20]}...")
            return csrf_token

        print("‚ùå CSRF —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–æ—Ä–º–µ")
        return None

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è CSRF —Ç–æ–∫–µ–Ω–∞: {e}")
        return None


def post_news_to_site_simple(news_text: str, image_path: str = None) -> bool:
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–º –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏"""
    if not login_to_site():
        return False

    csrf_token = get_csrf_token_for_create()
    if not csrf_token:
        return False

    create_url = f"{SITE_URL}/admin/news"
    title, body = extract_title_and_body(news_text)

    print("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –í–°–ï–• translatable –ø–æ–ª–µ–π Voyager...")
    print(f"üìù –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞: {create_url}")

    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –ø–µ—Ä–≤—ã—Ö 100 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞
    subtitle = body[:100] + "..." if len(body) > 100 else body

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SEO –ø–æ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ —Ç–µ–∫—Å—Ç–∞
    seo_title = title[:60]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è SEO
    seo_description = body[:160] if body else title[:160]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è SEO
    seo_keywords = "–∞–≥—Ä–æ, —Å–µ–ª—å—Å–∫–æ–µ —Ö–æ–∑—è–π—Å—Ç–≤–æ, –Ω–æ–≤–æ—Å—Ç–∏, –ê–ü–ö"  # –ë–∞–∑–æ–≤—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞

    # –ü–†–ê–í–ò–õ–¨–ù–´–ô —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –í–°–ï–• translatable –ø–æ–ª–µ–π –≤ Voyager
    data = {
        "_token": csrf_token,
        "i18n_selector": "ru",

        # –í–°–ï translatable –ø–æ–ª—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è Voyager
        "title_i18n": json.dumps({"ru": title, "kk": "", "en": "", "zh": ""}),
        "subtitle_i18n": json.dumps({"ru": subtitle, "kk": "", "en": "", "zh": ""}),
        "description_i18n": json.dumps({"ru": body, "kk": "", "en": "", "zh": ""}),
        "seo_title_i18n": json.dumps({"ru": seo_title, "kk": "", "en": "", "zh": ""}),
        "seo_description_i18n": json.dumps({"ru": seo_description, "kk": "", "en": "", "zh": ""}),
        "seo_keywords_i18n": json.dumps({"ru": seo_keywords, "kk": "", "en": "", "zh": ""}),

        # –¢–∞–∫–∂–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–±—ã—á–Ω—ã–µ –ø–æ–ª—è
        "title": title,
        "subtitle": subtitle,  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫
        "description": body,
        "seo_title": seo_title,
        "seo_description": seo_description,
        "seo_keywords": seo_keywords,

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω—É–∂–Ω—ã
        "status": "PUBLISHED",
        "category_id": "",  # –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        "author_id": "",  # –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å ID –∞–≤—Ç–æ—Ä–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        "published_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),

        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø–æ–ª—è
        "redirect_to": "",
        "model_name": "App\\Models\\News",
        "model_id": "",
        "type_slug": "news",
    }

    files = {}
    if image_path and os.path.exists(image_path):
        try:
            # –û—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            files["image"] = open(image_path, "rb")
            print(f"üñºÔ∏è –û—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")

            # SEO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–µ–º –∂–µ —Å–∞–º—ã–º)
            files["seo_image"] = open(image_path, "rb")
            print(f"üîç SEO –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")

        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}")
    else:
        print("‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ –ø—É—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω")

    try:
        response = session.post(create_url, data=data, files=files, timeout=30)

        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
        for file_obj in files.values():
            file_obj.close()

        print(f"üì° –û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {response.status_code}")

        if response.status_code == 500:
            print("‚ùå –û—à–∏–±–∫–∞ 500 - –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
            error_content = response.text
            with open("error_detailed.html", "w", encoding="utf-8") as f:
                f.write(error_content)

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
            if "Invalid Translatable field" in error_content:
                print("üîç –ü—Ä–æ–±–ª–µ–º–∞ —Å translatable –ø–æ–ª—è–º–∏!")

            return False

        if response.status_code in (200, 302):
            if response.status_code == 302:
                location = response.headers.get('Location', '')
                if 'admin/news' in location or 'success' in location.lower():
                    print("‚úÖ –ù–æ–≤–æ—Å—Ç—å —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞ (—Ä–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π)!")
                    return True
                else:
                    print(f"‚ö†Ô∏è –†–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞: {location}")
                    return True

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
            success_indicators = ['—É—Å–ø–µ—Ö', 'success', '—Å–æ–∑–¥–∞–Ω', 'created']
            if any(indicator in response.text.lower() for indicator in success_indicators):
                print("‚úÖ –ù–æ–≤–æ—Å—Ç—å —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!")
                return True

            # –ï—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω—ã—Ö –æ—à–∏–±–æ–∫, —Å—á–∏—Ç–∞–µ–º —É—Å–ø–µ—à–Ω—ã–º
            error_indicators = ['error', '–æ—à–∏–±–∫–∞', 'exception', 'invalid']
            if not any(indicator in response.text.lower() for indicator in error_indicators):
                print("‚úÖ –ù–æ–≤–æ—Å—Ç—å —Å–æ–∑–¥–∞–Ω–∞ (–Ω–µ—Ç –æ—à–∏–±–æ–∫ –≤ –æ—Ç–≤–µ—Ç–µ)!")
                return True

            print("‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ –æ—Ç–≤–µ—Ç–µ")
            return False
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {response.status_code}")
            return False

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
        return False
def post_news_to_site(news_text: str, image_path: str = None) -> bool:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–∏"""
    return post_news_to_site_simple(news_text, image_path)


def post_news_to_site_alternative(news_text: str, image_path: str = None) -> bool:
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ - –æ—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ –∏–º–∏—Ç–∞—Ü–∏—é –±—Ä–∞—É–∑–µ—Ä–∞"""
    if not login_to_site():
        return False

    csrf_token = get_csrf_token_for_create()
    if not csrf_token:
        return False

    create_url = f"{SITE_URL}/admin/news"
    title, body = extract_title_and_body(news_text)

    print("üîÑ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä translatable –ø–æ–ª–µ–π...")

    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä translatable –ø–æ–ª–µ–π
    data = {
        "_token": csrf_token,
        "i18n_selector": "ru",

        # –¢–æ–ª—å–∫–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ translatable –ø–æ–ª—è
        "title_i18n": json.dumps({"ru": title, "kk": "", "en": "", "zh": ""}),
        "description_i18n": json.dumps({"ru": body, "kk": "", "en": "", "zh": ""}),

        # –û–±—ã—á–Ω—ã–µ –ø–æ–ª—è
        "title": title,
        "description": body,
    }

    files = {}
    if image_path:
        try:
            files["image"] = open(image_path, "rb")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}")

    try:
        response = session.post(create_url, data=data, files=files, timeout=20)

        if files:
            files["image"].close()

        print(f"üì° –û—Ç–≤–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞: {response.status_code}")

        if response.status_code in (200, 302):
            print("‚úÖ –ù–æ–≤–æ—Å—Ç—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º –º–µ—Ç–æ–¥–æ–º!")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞: {response.status_code}")
            return False

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞: {e}")
        return False

def analyze_create_form():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º—É —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
    if not login_to_site():
        return

    create_url = f"{SITE_URL}/admin/news/create"
    try:
        resp = session.get(create_url, timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")

        print("üîç –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ä–º—ã —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–∏:")

        # –ò—â–µ–º –≤—Å–µ –ø–æ–ª—è —Ñ–æ—Ä–º—ã
        form = soup.find('form')
        if form:
            inputs = form.find_all('input')
            textareas = form.find_all('textarea')
            selects = form.find_all('select')

            print(f"üìã –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π:")
            print(f"Inputs: {len(inputs)}")
            for inp in inputs:
                name = inp.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')
                type_ = inp.get('type', '–±–µ–∑ —Ç–∏–ø–∞')
                print(f"  - {name} (type: {type_})")

            print(f"Textareas: {len(textareas)}")
            for ta in textareas:
                name = ta.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')
                print(f"  - {name}")

            print(f"Selects: {len(selects)}")
            for sel in selects:
                name = sel.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')
                print(f"  - {name}")

        # –ò—â–µ–º CSRF —Ç–æ–∫–µ–Ω
        token_tag = soup.find("meta", {"name": "csrf-token"})
        if token_tag:
            print(f"‚úÖ CSRF —Ç–æ–∫–µ–Ω –Ω–∞–π–¥–µ–Ω: {token_tag['content'][:20]}...")
        else:
            print("‚ùå CSRF —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ä–º—ã: {e}")


def check_required_fields():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è —Ñ–æ—Ä–º—ã"""
    if not login_to_site():
        return

    create_url = f"{SITE_URL}/admin/news/create"
    try:
        resp = session.get(create_url, timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")

        print("üîç –ü–æ–∏—Å–∫ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π:")

        # –ò—â–µ–º –ø–æ–ª—è —Å –∞—Ç—Ä–∏–±—É—Ç–æ–º required
        required_fields = []
        all_inputs = soup.find_all('input')
        all_textareas = soup.find_all('textarea')
        all_selects = soup.find_all('select')

        for field in all_inputs + all_textareas + all_selects:
            if field.get('required'):
                name = field.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')
                required_fields.append(name)
                field_type = field.name
                print(f"‚ö†Ô∏è –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {name} (—Ç–∏–ø: {field_type})")

        if not required_fields:
            print("‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        return required_fields

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–µ–π: {e}")
        return []


def analyze_real_form_fields():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –ø–æ–ª—è —Ñ–æ—Ä–º—ã —á–µ—Ä–µ–∑ JavaScript –∏–ª–∏ HTML"""
    if not login_to_site():
        return

    create_url = f"{SITE_URL}/admin/news/create"
    try:
        resp = session.get(create_url, timeout=10)

        print("üîç –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–æ—Ä–º—ã:")
        print("=" * 50)

        # –ò—â–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–ª—è –≤–≤–æ–¥–∞
        soup = BeautifulSoup(resp.text, "html.parser")

        # –í—Å–µ input —ç–ª–µ–º–µ–Ω—Ç—ã
        print("üìã INPUT –ø–æ–ª—è:")
        inputs = soup.find_all('input')
        for inp in inputs:
            name = inp.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')
            input_type = inp.get('type', 'text')
            value = inp.get('value', '')
            placeholder = inp.get('placeholder', '')
            if 'i18n' in name:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ translatable –ø–æ–ª—è
                print(f"  - name: '{name}', type: '{input_type}', value: '{value}', placeholder: '{placeholder}'")

        # –í—Å–µ textarea —ç–ª–µ–º–µ–Ω—Ç—ã
        print("\nüìã TEXTAREA –ø–æ–ª—è:")
        textareas = soup.find_all('textarea')
        for ta in textareas:
            name = ta.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')
            placeholder = ta.get('placeholder', '')
            if 'i18n' in name:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ translatable –ø–æ–ª—è
                print(f"  - name: '{name}', placeholder: '{placeholder}'")

        # –í—Å–µ select —ç–ª–µ–º–µ–Ω—Ç—ã
        print("\nüìã SELECT –ø–æ–ª—è:")
        selects = soup.find_all('select')
        for sel in selects:
            name = sel.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')
            if 'i18n' in name:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ translatable –ø–æ–ª—è
                options = sel.find_all('option')
                print(f"  - name: '{name}', options: {len(options)}")
                for opt in options[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 –æ–ø—Ü–∏–∏
                    print(f"    * {opt.get('value', '')} - {opt.text}")

        # –ò—â–µ–º JavaScript –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        print("\nüîç JavaScript –¥–∞–Ω–Ω—ã–µ:")
        scripts = soup.find_all('script')
        for script in scripts:
            if script.string:
                js_content = script.string
                # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è translatable –ø–æ–ª–µ–π –≤ JS
                if any(field in js_content for field in ['i18n', 'translatable']):
                    lines = js_content.split('\n')
                    for line in lines[:20]:  # –ü–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫
                        if any(field in line for field in ['i18n', 'translatable']):
                            print(f"  JS: {line.strip()}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ä–º—ã: {e}")

def test_form_manually():
    """–†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º—ã"""
    if not login_to_site():
        return

    create_url = f"{SITE_URL}/admin/news/create"
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–æ–∑–¥–∞–Ω–∏—è
        resp = session.get(create_url)
        soup = BeautifulSoup(resp.text, "html.parser")

        print("üß™ –†—É—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–æ—Ä–º—ã:")
        print("=" * 50)

        # –ò—â–µ–º —Ñ–æ—Ä–º—É
        form = soup.find('form')
        if form:
            action = form.get('action', '')
            method = form.get('method', 'post')
            print(f"–§–æ—Ä–º–∞: action='{action}', method='{method}'")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –ø–æ–ª—è —Ñ–æ—Ä–º—ã
            inputs = form.find_all('input')
            print(f"–í—Å–µ–≥–æ input –ø–æ–ª–µ–π: {len(inputs)}")

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
            text_inputs = [inp for inp in inputs if inp.get('type') == 'text']
            hidden_inputs = [inp for inp in inputs if inp.get('type') == 'hidden']
            file_inputs = [inp for inp in inputs if inp.get('type') == 'file']

            print(f"Text –ø–æ–ª—è: {len(text_inputs)}")
            for inp in text_inputs:
                name = inp.get('name')
                placeholder = inp.get('placeholder', '')
                print(f"  - {name}: '{placeholder}'")

            print(f"Hidden –ø–æ–ª—è: {len(hidden_inputs)}")
            for inp in hidden_inputs[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                name = inp.get('name')
                value = inp.get('value', '')[:50]
                print(f"  - {name}: '{value}'")

            print(f"File –ø–æ–ª—è: {len(file_inputs)}")
            for inp in file_inputs:
                name = inp.get('name')
                print(f"  - {name}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º textarea
        textareas = soup.find_all('textarea')
        print(f"Textarea –ø–æ–ª—è: {len(textareas)}")
        for ta in textareas:
            name = ta.get('name')
            placeholder = ta.get('placeholder', '')
            print(f"  - {name}: '{placeholder}'")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")


def debug_form_submission():
    """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ä–º—ã"""
    if not login_to_site():
        return

    create_url = f"{SITE_URL}/admin/news/create"
    try:
        print("üêõ –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–æ—Ä–º–µ:")
        print("=" * 50)

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        resp = session.get(create_url)
        soup = BeautifulSoup(resp.text, "html.parser")

        # –ù–∞—Ö–æ–¥–∏–º —Ñ–æ—Ä–º—É
        form = soup.find('form')
        if form:
            action = form.get('action', '')
            method = form.get('method', '')
            print(f"–§–æ—Ä–º–∞ action: {action}")
            print(f"–§–æ—Ä–º–∞ method: {method}")

            # –í—Å–µ –ø–æ–ª—è —Ñ–æ—Ä–º—ã
            inputs = form.find_all('input')
            print(f"–í—Å–µ–≥–æ input –ø–æ–ª–µ–π: {len(inputs)}")

            for inp in inputs:
                name = inp.get('name', '')
                input_type = inp.get('type', '')
                value = inp.get('value', '')[:50]
                if name:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª—è —Å –∏–º–µ–Ω–µ–º
                    print(f"  {name} (type: {input_type}) = '{value}'")

            # Textareas
            textareas = form.find_all('textarea')
            print(f"Textarea –ø–æ–ª–µ–π: {len(textareas)}")
            for ta in textareas:
                name = ta.get('name', '')
                if name:
                    print(f"  {name}")

        else:
            print("‚ùå –§–æ—Ä–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ª–∞–¥–∫–∏: {e}")


def find_correct_form_endpoint():
    """–ü–æ–∏—Å–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ endpoint –¥–ª—è —Ñ–æ—Ä–º—ã"""
    if not login_to_site():
        return None

    create_url = f"{SITE_URL}/admin/news/create"
    try:
        resp = session.get(create_url)
        soup = BeautifulSoup(resp.text, "html.parser")

        # –ò—â–µ–º JavaScript –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å endpoint
        scripts = soup.find_all('script')
        for script in scripts:
            if script.string:
                content = script.string
                if 'action' in content and 'news' in content:
                    print("üîç –ù–∞–π–¥–µ–Ω –≤–æ–∑–º–æ–∂–Ω—ã–π endpoint –≤ JS:")
                    lines = content.split('\n')
                    for line in lines:
                        if 'action' in line and 'news' in line:
                            print(f"  JS: {line.strip()}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ endpoints
        endpoints = [
            f"{SITE_URL}/admin/news",
            f"{SITE_URL}/admin/news/store",
            f"{SITE_URL}/admin/news/save",
            f"{SITE_URL}/admin/news/create"
        ]

        for endpoint in endpoints:
            print(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º endpoint: {endpoint}")
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∑–¥–µ—Å—å

        return f"{SITE_URL}/admin/news"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ endpoint: {e}")
        return None


def debug_current_form():
    """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–æ—Ä–º—ã"""
    if not login_to_site():
        return

    create_url = f"{SITE_URL}/admin/news/create"
    try:
        resp = session.get(create_url)
        soup = BeautifulSoup(resp.text, "html.parser")

        print("üîç –¢–µ–∫—É—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–æ—Ä–º—ã:")
        form = soup.find('form')
        if form:
            # –ù–∞–π—Ç–∏ –≤—Å–µ –ø–æ–ª—è —Å –∏–º–µ–Ω–µ–º —Å–æ–¥–µ—Ä–∂–∞—â–∏–º 'i18n'
            i18n_fields = form.find_all(attrs={"name": lambda x: x and 'i18n' in x})
            print(f"–ù–∞–π–¥–µ–Ω–æ i18n –ø–æ–ª–µ–π: {len(i18n_fields)}")
            for field in i18n_fields:
                print(f"  - {field.get('name')}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ª–∞–¥–∫–∏: {e}")


def test_all_translatable_fields():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫—É –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö translatable –ø–æ–ª–µ–π"""
    if not login_to_site():
        return False

    csrf_token = get_csrf_token_for_create()
    if not csrf_token:
        return False

    create_url = f"{SITE_URL}/admin/news"
    title = "–¢–µ—Å—Ç–æ–≤–∞—è –Ω–æ–≤–æ—Å—Ç—å"
    body = "–¢–µ—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏"

    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ translatable –ø–æ–ª—è...")

    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ translatable –ø–æ–ª–µ–π
    test_cases = [
        {
            "name": "–¢–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è",
            "data": {
                "_token": csrf_token,
                "i18n_selector": "ru",
                "title_i18n": json.dumps({"ru": title}),
                "description_i18n": json.dumps({"ru": body}),
            }
        },
        {
            "name": "–° subtitle",
            "data": {
                "_token": csrf_token,
                "i18n_selector": "ru",
                "title_i18n": json.dumps({"ru": title}),
                "subtitle_i18n": json.dumps({"ru": "–¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫"}),
                "description_i18n": json.dumps({"ru": body}),
            }
        },
        {
            "name": "–¢–æ–ª—å–∫–æ –æ–±—ã—á–Ω—ã–µ –ø–æ–ª—è",
            "data": {
                "_token": csrf_token,
                "title": title,
                "description": body,
            }
        }
    ]

    for i, test_case in enumerate(test_cases):
        print(f"\nüîç –¢–µ—Å—Ç {i + 1}: {test_case['name']}")
        try:
            response = session.post(create_url, data=test_case['data'], timeout=10)
            print(f"üì° –û—Ç–≤–µ—Ç: {response.status_code}")

            if response.status_code == 500:
                print("‚ùå –û—à–∏–±–∫–∞ 500")
            elif response.status_code in (200, 302):
                print("‚úÖ –£—Å–ø–µ—Ö!")
                return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

    return False


def debug_form_submission_detailed():
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ä–º—ã"""
    if not login_to_site():
        return

    create_url = f"{SITE_URL}/admin/news/create"
    try:
        resp = session.get(create_url)
        soup = BeautifulSoup(resp.text, "html.parser")

        print("üîç –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ —Ñ–æ—Ä–º—ã:")
        print("=" * 60)

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–∫—Ä—ã—Ç—ã–µ –ø–æ–ª—è —Å i18n
        hidden_i18n_fields = soup.find_all('input', {'type': 'hidden', 'name': lambda x: x and 'i18n' in x})
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ —Å–∫—Ä—ã—Ç—ã—Ö i18n –ø–æ–ª–µ–π: {len(hidden_i18n_fields)}")

        for field in hidden_i18n_fields:
            name = field.get('name')
            value = field.get('value', '')[:100]  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤
            print(f"  - {name}: {value}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        for field in hidden_i18n_fields:
            name = field.get('name')
            value = field.get('value', '')
            try:
                parsed = json.loads(value)
                print(f"  ‚úÖ {name}: –≤–∞–ª–∏–¥–Ω—ã–π JSON, –∫–ª—é—á–∏: {list(parsed.keys())}")
            except:
                print(f"  ‚ùå {name}: –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ª–∞–¥–∫–∏: {e}")


def analyze_image_upload():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ª—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    if not login_to_site():
        return

    create_url = f"{SITE_URL}/admin/news/create"
    try:
        resp = session.get(create_url)
        soup = BeautifulSoup(resp.text, "html.parser")

        print("üîç –ê–Ω–∞–ª–∏–∑ –ø–æ–ª–µ–π –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
        print("=" * 50)

        # –ò—â–µ–º –≤—Å–µ –ø–æ–ª—è —Ç–∏–ø–∞ file
        file_inputs = soup.find_all('input', {'type': 'file'})
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤: {len(file_inputs)}")

        for file_input in file_inputs:
            name = file_input.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')
            accept = file_input.get('accept', '')
            print(f"  - –ü–æ–ª–µ: '{name}', –ø—Ä–∏–Ω–∏–º–∞–µ—Ç: '{accept}'")

        # –ò—â–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –ø–æ–ª—è
        image_related = soup.find_all(['input', 'textarea', 'select'],
                                      attrs={'name': lambda x: x and 'image' in x.lower()})
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ–π —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏: {len(image_related)}")

        for field in image_related:
            name = field.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')
            field_type = field.name
            print(f"  - {name} (—Ç–∏–ø: {field_type})")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")